{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb99836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\aco\\\\research\\\\Asd-classification\\\\notebook', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\python312.zip', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\DLLs', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3', '', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', '..', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as plt\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from nlp_pipeline.feature_extraction import FeatureExtractor\n",
    "from nlp_pipeline.preprocess_text import TextPreprocessor\n",
    "from model.evaluate_model import ModelEvaluator\n",
    "from model.train_baseline import BaselineTrainer\n",
    "from interpretation.lime_interpreter import LimeTextInterpreter\n",
    "from interpretation.shap_interpreter import ShapInterpreter\n",
    "from nlp_pipeline.back_translator import BackTranslationAugmentor\n",
    "from nlp_pipeline.embedding_oversample import EmbeddingOversampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8d546",
   "metadata": {},
   "source": [
    "Load dataset + Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72694a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df = pd.read_csv('../data/feature/merged_final.csv', encoding='latin1')\n",
    "columns = ['label', 'transcription', 'total_words', 'unique_words', 'num_sentences',\n",
    "                   'stopwords', 'num_adjectives', 'num_nouns', 'num_verbs', 'num_adverbs',\n",
    "                   'type_token_ratio', 'avg_words_per_sentence']\n",
    "df = df[columns]\n",
    "augmentor = BackTranslationAugmentor()\n",
    "df_augmented = augmentor.augment_dataframe(df)\n",
    "print(df_augmented.head)\n",
    "df_augmented.to_csv('../data/feature/1_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151598b",
   "metadata": {},
   "source": [
    "Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22c7bd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tunjuk kaka coba</td>\n",
       "      <td>tunjuk kaka coba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inii!</td>\n",
       "      <td>ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapa namamu?</td>\n",
       "      <td>siapa nama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iyaaaa?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenalan duluu!</td>\n",
       "      <td>kenal duluu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transcription        clean_text\n",
       "0  Tunjuk kaka coba  tunjuk kaka coba\n",
       "1             Inii!               ini\n",
       "2     Siapa namamu?        siapa nama\n",
       "3           Iyaaaa?                  \n",
       "4    Kenalan duluu!       kenal duluu"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df = pd.read_csv('../data/feature/combined_augmented_asd.csv', encoding='latin1')\n",
    "text_preprocessor = TextPreprocessor()\n",
    "df['clean_text'] = df['transcription'].apply(text_preprocessor.preprocess)\n",
    "df[['transcription', 'clean_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1d86e",
   "metadata": {},
   "source": [
    "Ekstraksi fitur with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95046e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7970c6948b3f4991bf981a91733c74fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7aadd38e9647388a6d518b85b8d18b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b59d2cfad2443a89e9761986845434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6ebea5147c4e8db7d827b7a5393e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7180d7fb783d48e9931969e037278228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50d7db53f034d2fbc4064ad4306333d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69554fa5af9c401896e8d97533b7c9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5462738d04e543598731c8eadc04df35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc5fc4476754d68a525d566373172a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8380, 5000) (8380,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72557fd957c74325b7db4b1c05a79629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "extractor = FeatureExtractor()\n",
    "X = extractor.fit_transform_tfidf(df['clean_text'])\n",
    "y = df['label'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96aad2",
   "metadata": {},
   "source": [
    "Oversampling with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7520d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = extractor.fit_transform_tfidf(df['clean_text']).toarray()\n",
    "\n",
    "ling_cols = extractor.linguistic_cols\n",
    "X_ling = df[ling_cols].values\n",
    "\n",
    "y = (df['label'].str.upper().str.strip() == 'ASD').astype(int).values\n",
    "\n",
    "oversampler = EmbeddingOversampler()\n",
    "X_embed_bal, X_ling_bal, y_bal = oversampler.oversample(X_dense, X_ling, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdeb2d6",
   "metadata": {},
   "source": [
    "Ekstraksi fitur with IndoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2939d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor()\n",
    "X = extractor.encode_series_bert(df['clean_text'])\n",
    "y = df['label'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ec845",
   "metadata": {},
   "source": [
    "SVC WITH 5 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5fa12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Oversampled] Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.937     0.810     0.869       930\n",
      "           1      0.832     0.945     0.885       930\n",
      "\n",
      "    accuracy                          0.877      1860\n",
      "   macro avg      0.884     0.877     0.877      1860\n",
      "weighted avg      0.884     0.877     0.877      1860\n",
      "\n",
      "Confusion Matrix:\n",
      " [[753 177]\n",
      " [ 51 879]]\n",
      "Confusion Matrix (Fold 1):\n",
      "[[753 177]\n",
      " [ 51 879]]\n",
      "\n",
      "[Oversampled] Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.946     0.812     0.874       930\n",
      "           1      0.835     0.954     0.890       929\n",
      "\n",
      "    accuracy                          0.883      1859\n",
      "   macro avg      0.891     0.883     0.882      1859\n",
      "weighted avg      0.891     0.883     0.882      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[755 175]\n",
      " [ 43 886]]\n",
      "Confusion Matrix (Fold 2):\n",
      "[[755 175]\n",
      " [ 43 886]]\n",
      "\n",
      "[Oversampled] Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.923     0.845     0.882       930\n",
      "           1      0.857     0.929     0.892       929\n",
      "\n",
      "    accuracy                          0.887      1859\n",
      "   macro avg      0.890     0.887     0.887      1859\n",
      "weighted avg      0.890     0.887     0.887      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[786 144]\n",
      " [ 66 863]]\n",
      "Confusion Matrix (Fold 3):\n",
      "[[786 144]\n",
      " [ 66 863]]\n",
      "\n",
      "[Oversampled] Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     0.827     0.880       929\n",
      "           1      0.846     0.948     0.894       930\n",
      "\n",
      "    accuracy                          0.888      1859\n",
      "   macro avg      0.893     0.888     0.887      1859\n",
      "weighted avg      0.893     0.888     0.887      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[768 161]\n",
      " [ 48 882]]\n",
      "Confusion Matrix (Fold 4):\n",
      "[[768 161]\n",
      " [ 48 882]]\n",
      "\n",
      "[Oversampled] Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.941     0.826     0.880       929\n",
      "           1      0.845     0.948     0.894       930\n",
      "\n",
      "    accuracy                          0.887      1859\n",
      "   macro avg      0.893     0.887     0.887      1859\n",
      "weighted avg      0.893     0.887     0.887      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[767 162]\n",
      " [ 48 882]]\n",
      "Confusion Matrix (Fold 5):\n",
      "[[767 162]\n",
      " [ 48 882]]\n",
      "\n",
      "Mean Metrics (Oversampled):\n",
      "Accuracy : 0.8844\n",
      "Precision: 0.8430\n",
      "Recall   : 0.9449\n",
      "F1       : 0.8910\n",
      "\n",
      "Best Fold: Fold 4 with F1-score = 0.8941\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer()\n",
    "\n",
    "evaluator = ModelEvaluator(model_type='svm',pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180171f",
   "metadata": {},
   "source": [
    "USE THIS IF YOU NOT USING BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf2d372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil menyimpan!\n"
     ]
    }
   ],
   "source": [
    "final_model = trainer.train(X_embed_bal, y_bal)\n",
    "\n",
    "lime_interpreter = LimeTextInterpreter(\n",
    "    model=final_model,\n",
    "    vectorizer=extractor.get_tfidf_vectorizer(),\n",
    "    class_names=['NON ASD', 'ASD']\n",
    ")\n",
    "\n",
    "asd_samples = df[df['label'] == 'ASD'].sample(n=12, random_state=42)\n",
    "non_asd_samples = df[df['label'] == 'NON ASD'].sample(n=12, random_state=42)\n",
    "lime_samples = pd.concat([asd_samples, non_asd_samples]).reset_index(drop=True)\n",
    "\n",
    "lime_interpreter.save_lime_explanation_to_csv(lime_samples,\"../reports/lime_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb513db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaselineTrainer('svm').train(X,y)\n",
    "interpreter = ShapInterpreter(model=final_model)\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "texts = sampled_df['clean_text'].tolist()\n",
    "labels = sampled_df['label'].tolist()\n",
    "\n",
    "shap_values = interpreter.explain(texts)\n",
    "interpreter.save_shap_explanations_to_csv(\n",
    "    shap_values=shap_values,\n",
    "    texts=texts,\n",
    "    output_path=\"../reports/shap_results_SVM.csv\",\n",
    "    true_labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e7b83",
   "metadata": {},
   "source": [
    "LINEAR REGRETION WITH 5 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f0cd2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Oversampled] Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.921     0.794     0.853       930\n",
      "           1      0.819     0.932     0.872       930\n",
      "\n",
      "    accuracy                          0.863      1860\n",
      "   macro avg      0.870     0.863     0.862      1860\n",
      "weighted avg      0.870     0.863     0.862      1860\n",
      "\n",
      "Confusion Matrix:\n",
      " [[738 192]\n",
      " [ 63 867]]\n",
      "Confusion Matrix (Fold 1):\n",
      "[[738 192]\n",
      " [ 63 867]]\n",
      "\n",
      "[Oversampled] Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.940     0.797     0.863       930\n",
      "           1      0.824     0.949     0.882       929\n",
      "\n",
      "    accuracy                          0.873      1859\n",
      "   macro avg      0.882     0.873     0.872      1859\n",
      "weighted avg      0.882     0.873     0.872      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[741 189]\n",
      " [ 47 882]]\n",
      "Confusion Matrix (Fold 2):\n",
      "[[741 189]\n",
      " [ 47 882]]\n",
      "\n",
      "[Oversampled] Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.927     0.820     0.871       930\n",
      "           1      0.839     0.935     0.884       929\n",
      "\n",
      "    accuracy                          0.878      1859\n",
      "   macro avg      0.883     0.878     0.877      1859\n",
      "weighted avg      0.883     0.878     0.877      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[763 167]\n",
      " [ 60 869]]\n",
      "Confusion Matrix (Fold 3):\n",
      "[[763 167]\n",
      " [ 60 869]]\n",
      "\n",
      "[Oversampled] Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.938     0.800     0.863       929\n",
      "           1      0.826     0.947     0.882       930\n",
      "\n",
      "    accuracy                          0.874      1859\n",
      "   macro avg      0.882     0.874     0.873      1859\n",
      "weighted avg      0.882     0.874     0.873      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[743 186]\n",
      " [ 49 881]]\n",
      "Confusion Matrix (Fold 4):\n",
      "[[743 186]\n",
      " [ 49 881]]\n",
      "\n",
      "[Oversampled] Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.935     0.808     0.867       929\n",
      "           1      0.831     0.944     0.884       930\n",
      "\n",
      "    accuracy                          0.876      1859\n",
      "   macro avg      0.883     0.876     0.876      1859\n",
      "weighted avg      0.883     0.876     0.876      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[751 178]\n",
      " [ 52 878]]\n",
      "Confusion Matrix (Fold 5):\n",
      "[[751 178]\n",
      " [ 52 878]]\n",
      "\n",
      "Mean Metrics (Oversampled):\n",
      "Accuracy : 0.8727\n",
      "Precision: 0.8276\n",
      "Recall   : 0.9417\n",
      "F1       : 0.8810\n",
      "\n",
      "Best Fold: Fold 3 with F1-score = 0.8845\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer()\n",
    "evaluator = ModelEvaluator(pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trainer.train(X, y)\n",
    "\n",
    "lime_interpreter = LimeTextInterpreter(\n",
    "    model=final_model,\n",
    "    vectorizer=extractor.get_tfidf_vectorizer(),\n",
    "    class_names=['NON ASD', 'ASD']\n",
    ")\n",
    "\n",
    "asd_samples = df[df['label'] == 'ASD'].sample(n=12, random_state=42)\n",
    "non_asd_samples = df[df['label'] == 'NON ASD'].sample(n=12, random_state=42)\n",
    "lime_samples = pd.concat([asd_samples, non_asd_samples]).reset_index(drop=True)\n",
    "\n",
    "lime_interpreter.save_lime_explanation_to_csv(lime_samples,\"../reports/lime_results_LOGRES.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfd065",
   "metadata": {},
   "source": [
    "SVM WITH 10 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c1ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Oversampled] Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.958     0.832     0.891       465\n",
      "           1      0.852     0.963     0.904       465\n",
      "\n",
      "    accuracy                          0.898       930\n",
      "   macro avg      0.905     0.898     0.897       930\n",
      "weighted avg      0.905     0.898     0.897       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[387  78]\n",
      " [ 17 448]]\n",
      "Confusion Matrix (Fold 1):\n",
      "[[387  78]\n",
      " [ 17 448]]\n",
      "\n",
      "[Oversampled] Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.936     0.815     0.871       465\n",
      "           1      0.836     0.944     0.887       465\n",
      "\n",
      "    accuracy                          0.880       930\n",
      "   macro avg      0.886     0.880     0.879       930\n",
      "weighted avg      0.886     0.880     0.879       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[379  86]\n",
      " [ 26 439]]\n",
      "Confusion Matrix (Fold 2):\n",
      "[[379  86]\n",
      " [ 26 439]]\n",
      "\n",
      "[Oversampled] Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.943     0.860     0.900       465\n",
      "           1      0.872     0.948     0.908       465\n",
      "\n",
      "    accuracy                          0.904       930\n",
      "   macro avg      0.907     0.904     0.904       930\n",
      "weighted avg      0.907     0.904     0.904       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[400  65]\n",
      " [ 24 441]]\n",
      "Confusion Matrix (Fold 3):\n",
      "[[400  65]\n",
      " [ 24 441]]\n",
      "\n",
      "[Oversampled] Fold 4\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer()\n",
    "evaluator = ModelEvaluator(model_type='svm', n_splits= 10, random_state=32,pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a547db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trainer.train(X, y)\n",
    "\n",
    "lime_interpreter = LimeTextInterpreter(\n",
    "    model=final_model,\n",
    "    vectorizer=extractor.get_tfidf_vectorizer(),\n",
    "    class_names=['NON ASD', 'ASD']\n",
    ")\n",
    "\n",
    "asd_samples = df[df['label'] == 'ASD'].sample(n=12, random_state=42)\n",
    "non_asd_samples = df[df['label'] == 'NON ASD'].sample(n=12, random_state=42)\n",
    "lime_samples = pd.concat([asd_samples, non_asd_samples]).reset_index(drop=True)\n",
    "\n",
    "lime_interpreter.save_lime_explanation_to_csv(lime_samples,\"../reports/lime_results_SVM10FOLD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaselineTrainer('svm').train(X,y)\n",
    "interpreter = ShapInterpreter(model=final_model)\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "texts = sampled_df['clean_text'].tolist()\n",
    "labels = sampled_df['label'].tolist()\n",
    "\n",
    "shap_values = interpreter.explain(texts)\n",
    "interpreter.save_shap_explanations_to_csv(\n",
    "    shap_values=shap_values,\n",
    "    texts=texts,\n",
    "    output_path=\"../reports/shap_results_SVM_10_fold.csv\",\n",
    "    true_labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0fb88c",
   "metadata": {},
   "source": [
    "LINEAR REGRETION WITH 10 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaselineTrainer()\n",
    "evaluator = ModelEvaluator(n_splits= 10, random_state=32)\n",
    "\n",
    "results = evaluator.cross_validate(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c09c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaselineTrainer('svm').train(X,y)\n",
    "interpreter = ShapInterpreter(model=final_model)\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "texts = sampled_df['clean_text'].tolist()\n",
    "labels = sampled_df['label'].tolist()\n",
    "\n",
    "shap_values = interpreter.explain(texts)\n",
    "interpreter.save_shap_explanations_to_csv(\n",
    "    shap_values=shap_values,\n",
    "    texts=texts,\n",
    "    output_path=\"../reports/shap_results_Logres_10_fold.csv\",\n",
    "    true_labels=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ce051",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.visualize(shap_values= shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c494a",
   "metadata": {},
   "source": [
    "FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9582256",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor()\n",
    "X = extractor.extract_fused_features_bert(df)\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(model_type='svm', n_splits= 10, random_state=32)\n",
    "results = evaluator.cross_validate_with_confusionmatrix(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f670c",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaselineTrainer(model_type='svm')\n",
    "model = trainer.train(X, y)\n",
    "\n",
    "new_text = \"Apakah kamu suddah makan?\"\n",
    "clean_text = text_preprocessor.preprocess(new_text)\n",
    "X_new = extractor.encode_series_bert([clean_text])\n",
    "predicted_label = model.predict(X_new)[0]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0bd345",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"Aku takut aku takut aku takut aku takut aku takut aku takut aku takut\"\n",
    "clean_text = text_preprocessor.preprocess(new_text)\n",
    "X_new = extractor.encode_series_bert([clean_text])\n",
    "predicted_label = model.predict(X_new)[0]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
