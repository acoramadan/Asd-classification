{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bb99836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d:\\\\aco\\\\research\\\\Asd-classification\\\\notebook', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\python312.zip', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\DLLs', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3', '', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\MufliDevs\\\\anaconda3\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', '..']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as plt\n",
    "sys.path.append('..')\n",
    "print(sys.path)\n",
    "from nlp_pipeline.feature_extraction import FeatureExtractor\n",
    "from nlp_pipeline.preprocess_text import TextPreprocessor\n",
    "from model.evaluate_model import ModelEvaluator\n",
    "from model.train_baseline import BaselineTrainer\n",
    "from interpretation.lime_interpreter import LimeTextInterpreter\n",
    "from interpretation.shap_interpreter import ShapInterpreter\n",
    "from nlp_pipeline.back_translator import BackTranslationAugmentor\n",
    "from nlp_pipeline.embedding_oversample import EmbeddingOversampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8d546",
   "metadata": {},
   "source": [
    "Load dataset + Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72694a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df = pd.read_csv('../data/feature/merged_final.csv', encoding='latin1')\n",
    "columns = ['label', 'transcription', 'total_words', 'unique_words', 'num_sentences',\n",
    "                   'stopwords', 'num_adjectives', 'num_nouns', 'num_verbs', 'num_adverbs',\n",
    "                   'type_token_ratio', 'avg_words_per_sentence']\n",
    "df = df[columns]\n",
    "augmentor = BackTranslationAugmentor()\n",
    "df_augmented = augmentor.augment_dataframe(df)\n",
    "print(df_augmented.head)\n",
    "df_augmented.to_csv('../data/feature/1_augmented.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151598b",
   "metadata": {},
   "source": [
    "Preprocessing text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c7bd4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcription</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tunjuk kaka coba</td>\n",
       "      <td>tunjuk kaka coba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inii!</td>\n",
       "      <td>ini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapa namamu?</td>\n",
       "      <td>siapa nama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iyaaaa?</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenalan duluu!</td>\n",
       "      <td>kenal duluu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      transcription        clean_text\n",
       "0  Tunjuk kaka coba  tunjuk kaka coba\n",
       "1             Inii!               ini\n",
       "2     Siapa namamu?        siapa nama\n",
       "3           Iyaaaa?                  \n",
       "4    Kenalan duluu!       kenal duluu"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df = pd.read_csv('../data/feature/combined_augmented_asd.csv', encoding='latin1')\n",
    "text_preprocessor = TextPreprocessor()\n",
    "df['clean_text'] = df['transcription'].apply(text_preprocessor.preprocess)\n",
    "df[['transcription', 'clean_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cad1818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "NON ASD    4648\n",
       "ASD        3732\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c1d86e",
   "metadata": {},
   "source": [
    "Ekstraksi fitur with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95046e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor()\n",
    "X = extractor.fit_transform_tfidf(df['clean_text'])\n",
    "y = df['label'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f96aad2",
   "metadata": {},
   "source": [
    "Oversampling with TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7520d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dense = extractor.fit_transform_tfidf(df['clean_text']).toarray()\n",
    "\n",
    "ling_cols = extractor.linguistic_cols\n",
    "X_ling = df[ling_cols].values\n",
    "\n",
    "y = (df['label'].str.upper().str.strip() == 'ASD').astype(int).values\n",
    "\n",
    "oversampler = EmbeddingOversampler()\n",
    "X_embed_bal, X_ling_bal, y_bal = oversampler.oversample(X_dense, X_ling, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdeb2d6",
   "metadata": {},
   "source": [
    "Ekstraksi fitur with IndoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a2939d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fa991159f048f5958d8f8bd765b42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cec742ae804c82b1b71463716a4560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af617961adc243adb8a8b3a71f71be36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2f2fc1807241ce87c4469ef33e2bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1e935f255d4357993f2c80b835c581",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b332c27ddca4b50a3ed2740e7305610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5920e930a4483d8cf548562044c5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f69475b72ea44b3c9cc613323f9b08f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2685e38566a14a78bcb29b0a0f14fe1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db87588c538e456d89b6594531d1cf85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9296, 768) (8380,)\n"
     ]
    }
   ],
   "source": [
    "extractor = FeatureExtractor()\n",
    "X = extractor.encode_series_bert(df['clean_text'])\n",
    "y = (df['label'].str.upper().str.strip() == 'ASD').astype(int).values\n",
    "ling_cols = extractor.linguistic_cols\n",
    "X_ling = df[ling_cols].values\n",
    "oversampler = EmbeddingOversampler()\n",
    "X_embed_bal, X_ling_bal, y_bal = oversampler.oversample(X, X_ling, y)\n",
    "\n",
    "print(X_embed_bal.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ec845",
   "metadata": {},
   "source": [
    "SVC WITH 5 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c5fa12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Oversampled] Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.911     0.817     0.862       930\n",
      "           1      0.834     0.920     0.875       930\n",
      "\n",
      "    accuracy                          0.869      1860\n",
      "   macro avg      0.873     0.869     0.868      1860\n",
      "weighted avg      0.873     0.869     0.868      1860\n",
      "\n",
      "Confusion Matrix:\n",
      " [[760 170]\n",
      " [ 74 856]]\n",
      "Confusion Matrix (Fold 1):\n",
      "[[760 170]\n",
      " [ 74 856]]\n",
      "\n",
      "[Oversampled] Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.918     0.817     0.865       930\n",
      "           1      0.835     0.927     0.879       929\n",
      "\n",
      "    accuracy                          0.872      1859\n",
      "   macro avg      0.876     0.872     0.872      1859\n",
      "weighted avg      0.877     0.872     0.872      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[760 170]\n",
      " [ 68 861]]\n",
      "Confusion Matrix (Fold 2):\n",
      "[[760 170]\n",
      " [ 68 861]]\n",
      "\n",
      "[Oversampled] Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.824     0.866       930\n",
      "           1      0.839     0.921     0.878       929\n",
      "\n",
      "    accuracy                          0.873      1859\n",
      "   macro avg      0.876     0.873     0.872      1859\n",
      "weighted avg      0.876     0.873     0.872      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[766 164]\n",
      " [ 73 856]]\n",
      "Confusion Matrix (Fold 3):\n",
      "[[766 164]\n",
      " [ 73 856]]\n",
      "\n",
      "[Oversampled] Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.919     0.822     0.868       929\n",
      "           1      0.839     0.928     0.882       930\n",
      "\n",
      "    accuracy                          0.875      1859\n",
      "   macro avg      0.879     0.875     0.875      1859\n",
      "weighted avg      0.879     0.875     0.875      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[764 165]\n",
      " [ 67 863]]\n",
      "Confusion Matrix (Fold 4):\n",
      "[[764 165]\n",
      " [ 67 863]]\n",
      "\n",
      "[Oversampled] Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.912     0.832     0.870       929\n",
      "           1      0.846     0.919     0.881       930\n",
      "\n",
      "    accuracy                          0.876      1859\n",
      "   macro avg      0.879     0.876     0.875      1859\n",
      "weighted avg      0.879     0.876     0.876      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[773 156]\n",
      " [ 75 855]]\n",
      "Confusion Matrix (Fold 5):\n",
      "[[773 156]\n",
      " [ 75 855]]\n",
      "\n",
      "Mean Metrics (Oversampled):\n",
      "Accuracy : 0.8728\n",
      "Precision: 0.8388\n",
      "Recall   : 0.9232\n",
      "F1       : 0.8789\n",
      "\n",
      "Best Fold: Fold 4 with F1-score = 0.8815\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer()\n",
    "\n",
    "evaluator = ModelEvaluator(model_type='svm',pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6180171f",
   "metadata": {},
   "source": [
    "USE THIS IF YOU NOT USING BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trainer.train(X_embed_bal, y_bal)\n",
    "\n",
    "lime_interpreter = LimeTextInterpreter(\n",
    "    model=final_model,\n",
    "    vectorizer=extractor.get_tfidf_vectorizer(),\n",
    "    class_names=['NON ASD', 'ASD']\n",
    ")\n",
    "\n",
    "asd_samples = df[df['label'] == 'ASD'].sample(n=12, random_state=42)\n",
    "non_asd_samples = df[df['label'] == 'NON ASD'].sample(n=12, random_state=42)\n",
    "lime_samples = pd.concat([asd_samples, non_asd_samples]).reset_index(drop=True)\n",
    "\n",
    "lime_interpreter.save_lime_explanation_to_csv(lime_samples,\"../reports/lime_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb513db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaselineTrainer('svm').train(X,y)\n",
    "interpreter = ShapInterpreter(model=final_model)\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "texts = sampled_df['clean_text'].tolist()\n",
    "labels = sampled_df['label'].tolist()\n",
    "\n",
    "shap_values = interpreter.explain(texts)\n",
    "interpreter.save_shap_explanations_to_csv(\n",
    "    shap_values=shap_values,\n",
    "    texts=texts,\n",
    "    output_path=\"../reports/shap_results_SVM.csv\",\n",
    "    true_labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e7b83",
   "metadata": {},
   "source": [
    "LINEAR REGRETION WITH 5 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f0cd2fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Oversampled] Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.893     0.824     0.857       930\n",
      "           1      0.836     0.901     0.867       930\n",
      "\n",
      "    accuracy                          0.862      1860\n",
      "   macro avg      0.865     0.862     0.862      1860\n",
      "weighted avg      0.865     0.862     0.862      1860\n",
      "\n",
      "Confusion Matrix:\n",
      " [[766 164]\n",
      " [ 92 838]]\n",
      "Confusion Matrix (Fold 1):\n",
      "[[766 164]\n",
      " [ 92 838]]\n",
      "\n",
      "[Oversampled] Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     0.819     0.862       930\n",
      "           1      0.835     0.918     0.875       929\n",
      "\n",
      "    accuracy                          0.869      1859\n",
      "   macro avg      0.872     0.869     0.868      1859\n",
      "weighted avg      0.872     0.869     0.868      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[762 168]\n",
      " [ 76 853]]\n",
      "Confusion Matrix (Fold 2):\n",
      "[[762 168]\n",
      " [ 76 853]]\n",
      "\n",
      "[Oversampled] Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.895     0.828     0.860       930\n",
      "           1      0.840     0.903     0.870       929\n",
      "\n",
      "    accuracy                          0.866      1859\n",
      "   macro avg      0.868     0.866     0.865      1859\n",
      "weighted avg      0.868     0.866     0.865      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[770 160]\n",
      " [ 90 839]]\n",
      "Confusion Matrix (Fold 3):\n",
      "[[770 160]\n",
      " [ 90 839]]\n",
      "\n",
      "[Oversampled] Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.906     0.822     0.862       929\n",
      "           1      0.838     0.915     0.875       930\n",
      "\n",
      "    accuracy                          0.869      1859\n",
      "   macro avg      0.872     0.869     0.868      1859\n",
      "weighted avg      0.872     0.869     0.868      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[764 165]\n",
      " [ 79 851]]\n",
      "Confusion Matrix (Fold 4):\n",
      "[[764 165]\n",
      " [ 79 851]]\n",
      "\n",
      "[Oversampled] Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.904     0.842     0.872       929\n",
      "           1      0.852     0.911     0.880       930\n",
      "\n",
      "    accuracy                          0.876      1859\n",
      "   macro avg      0.878     0.876     0.876      1859\n",
      "weighted avg      0.878     0.876     0.876      1859\n",
      "\n",
      "Confusion Matrix:\n",
      " [[782 147]\n",
      " [ 83 847]]\n",
      "Confusion Matrix (Fold 5):\n",
      "[[782 147]\n",
      " [ 83 847]]\n",
      "\n",
      "Mean Metrics (Oversampled):\n",
      "Accuracy : 0.8683\n",
      "Precision: 0.8403\n",
      "Recall   : 0.9096\n",
      "F1       : 0.8736\n",
      "\n",
      "Best Fold: Fold 5 with F1-score = 0.8805\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer()\n",
    "evaluator = ModelEvaluator(pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf5bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trainer.train(X, y)\n",
    "\n",
    "lime_interpreter = LimeTextInterpreter(\n",
    "    model=final_model,\n",
    "    vectorizer=extractor.get_tfidf_vectorizer(),\n",
    "    class_names=['NON ASD', 'ASD']\n",
    ")\n",
    "\n",
    "asd_samples = df[df['label'] == 'ASD'].sample(n=12, random_state=42)\n",
    "non_asd_samples = df[df['label'] == 'NON ASD'].sample(n=12, random_state=42)\n",
    "lime_samples = pd.concat([asd_samples, non_asd_samples]).reset_index(drop=True)\n",
    "\n",
    "lime_interpreter.save_lime_explanation_to_csv(lime_samples,\"../reports/lime_results_LOGRES.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcfd065",
   "metadata": {},
   "source": [
    "SVM WITH 10 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59c1ca05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Oversampled] Fold 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.928     0.834     0.879       465\n",
      "           1      0.850     0.935     0.890       465\n",
      "\n",
      "    accuracy                          0.885       930\n",
      "   macro avg      0.889     0.885     0.885       930\n",
      "weighted avg      0.889     0.885     0.885       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[388  77]\n",
      " [ 30 435]]\n",
      "Confusion Matrix (Fold 1):\n",
      "[[388  77]\n",
      " [ 30 435]]\n",
      "\n",
      "[Oversampled] Fold 2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.933     0.804     0.864       465\n",
      "           1      0.828     0.942     0.881       465\n",
      "\n",
      "    accuracy                          0.873       930\n",
      "   macro avg      0.880     0.873     0.873       930\n",
      "weighted avg      0.880     0.873     0.873       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[374  91]\n",
      " [ 27 438]]\n",
      "Confusion Matrix (Fold 2):\n",
      "[[374  91]\n",
      " [ 27 438]]\n",
      "\n",
      "[Oversampled] Fold 3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.921     0.847     0.882       465\n",
      "           1      0.859     0.927     0.891       465\n",
      "\n",
      "    accuracy                          0.887       930\n",
      "   macro avg      0.890     0.887     0.887       930\n",
      "weighted avg      0.890     0.887     0.887       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[394  71]\n",
      " [ 34 431]]\n",
      "Confusion Matrix (Fold 3):\n",
      "[[394  71]\n",
      " [ 34 431]]\n",
      "\n",
      "[Oversampled] Fold 4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.899     0.826     0.861       465\n",
      "           1      0.839     0.908     0.872       465\n",
      "\n",
      "    accuracy                          0.867       930\n",
      "   macro avg      0.869     0.867     0.866       930\n",
      "weighted avg      0.869     0.867     0.866       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[384  81]\n",
      " [ 43 422]]\n",
      "Confusion Matrix (Fold 4):\n",
      "[[384  81]\n",
      " [ 43 422]]\n",
      "\n",
      "[Oversampled] Fold 5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.906     0.852     0.878       465\n",
      "           1      0.860     0.912     0.885       465\n",
      "\n",
      "    accuracy                          0.882       930\n",
      "   macro avg      0.883     0.882     0.882       930\n",
      "weighted avg      0.883     0.882     0.882       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[396  69]\n",
      " [ 41 424]]\n",
      "Confusion Matrix (Fold 5):\n",
      "[[396  69]\n",
      " [ 41 424]]\n",
      "\n",
      "[Oversampled] Fold 6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.921     0.781     0.845       465\n",
      "           1      0.810     0.933     0.867       465\n",
      "\n",
      "    accuracy                          0.857       930\n",
      "   macro avg      0.866     0.857     0.856       930\n",
      "weighted avg      0.866     0.857     0.856       930\n",
      "\n",
      "Confusion Matrix:\n",
      " [[363 102]\n",
      " [ 31 434]]\n",
      "Confusion Matrix (Fold 6):\n",
      "[[363 102]\n",
      " [ 31 434]]\n",
      "\n",
      "[Oversampled] Fold 7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.912     0.826     0.867       465\n",
      "           1      0.841     0.920     0.879       464\n",
      "\n",
      "    accuracy                          0.873       929\n",
      "   macro avg      0.876     0.873     0.873       929\n",
      "weighted avg      0.876     0.873     0.873       929\n",
      "\n",
      "Confusion Matrix:\n",
      " [[384  81]\n",
      " [ 37 427]]\n",
      "Confusion Matrix (Fold 7):\n",
      "[[384  81]\n",
      " [ 37 427]]\n",
      "\n",
      "[Oversampled] Fold 8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.913     0.834     0.872       465\n",
      "           1      0.847     0.920     0.882       464\n",
      "\n",
      "    accuracy                          0.877       929\n",
      "   macro avg      0.880     0.877     0.877       929\n",
      "weighted avg      0.880     0.877     0.877       929\n",
      "\n",
      "Confusion Matrix:\n",
      " [[388  77]\n",
      " [ 37 427]]\n",
      "Confusion Matrix (Fold 8):\n",
      "[[388  77]\n",
      " [ 37 427]]\n",
      "\n",
      "[Oversampled] Fold 9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.919     0.828     0.871       464\n",
      "           1      0.843     0.927     0.883       465\n",
      "\n",
      "    accuracy                          0.877       929\n",
      "   macro avg      0.881     0.877     0.877       929\n",
      "weighted avg      0.881     0.877     0.877       929\n",
      "\n",
      "Confusion Matrix:\n",
      " [[384  80]\n",
      " [ 34 431]]\n",
      "Confusion Matrix (Fold 9):\n",
      "[[384  80]\n",
      " [ 34 431]]\n",
      "\n",
      "[Oversampled] Fold 10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.912     0.828     0.868       464\n",
      "           1      0.843     0.920     0.880       465\n",
      "\n",
      "    accuracy                          0.874       929\n",
      "   macro avg      0.877     0.874     0.874       929\n",
      "weighted avg      0.877     0.874     0.874       929\n",
      "\n",
      "Confusion Matrix:\n",
      " [[384  80]\n",
      " [ 37 428]]\n",
      "Confusion Matrix (Fold 10):\n",
      "[[384  80]\n",
      " [ 37 428]]\n",
      "\n",
      "Mean Metrics (Oversampled):\n",
      "Accuracy : 0.8752\n",
      "Precision: 0.8419\n",
      "Recall   : 0.9245\n",
      "F1       : 0.8811\n",
      "\n",
      "Best Fold: Fold 3 with F1-score = 0.8914\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer()\n",
    "evaluator = ModelEvaluator(model_type='svm', n_splits= 10, random_state=32,pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a547db",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = trainer.train(X, y)\n",
    "\n",
    "lime_interpreter = LimeTextInterpreter(\n",
    "    model=final_model,\n",
    "    vectorizer=extractor.get_tfidf_vectorizer(),\n",
    "    class_names=['NON ASD', 'ASD']\n",
    ")\n",
    "\n",
    "asd_samples = df[df['label'] == 'ASD'].sample(n=12, random_state=42)\n",
    "non_asd_samples = df[df['label'] == 'NON ASD'].sample(n=12, random_state=42)\n",
    "lime_samples = pd.concat([asd_samples, non_asd_samples]).reset_index(drop=True)\n",
    "\n",
    "lime_interpreter.save_lime_explanation_to_csv(lime_samples,\"../reports/lime_results_SVM10FOLD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaselineTrainer('svm').train(X,y)\n",
    "interpreter = ShapInterpreter(model=final_model)\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "texts = sampled_df['clean_text'].tolist()\n",
    "labels = sampled_df['label'].tolist()\n",
    "\n",
    "shap_values = interpreter.explain(texts)\n",
    "interpreter.save_shap_explanations_to_csv(\n",
    "    shap_values=shap_values,\n",
    "    texts=texts,\n",
    "    output_path=\"../reports/shap_results_SVM_10_fold.csv\",\n",
    "    true_labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0fb88c",
   "metadata": {},
   "source": [
    "LINEAR REGRETION WITH 10 FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = BaselineTrainer()\n",
    "evaluator = ModelEvaluator(n_splits= 10, random_state=32,pos_label=1)\n",
    "\n",
    "results = evaluator.cross_validate_oversample_with_confusionmatrix(X_embed_bal,y_bal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c09c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = BaselineTrainer('svm').train(X,y)\n",
    "interpreter = ShapInterpreter(model=final_model)\n",
    "sampled_df = df.sample(n=100, random_state=42)\n",
    "texts = sampled_df['clean_text'].tolist()\n",
    "labels = sampled_df['label'].tolist()\n",
    "\n",
    "shap_values = interpreter.explain(texts)\n",
    "interpreter.save_shap_explanations_to_csv(\n",
    "    shap_values=shap_values,\n",
    "    texts=texts,\n",
    "    output_path=\"../reports/shap_results_Logres_10_fold.csv\",\n",
    "    true_labels=labels\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ce051",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.visualize(shap_values= shap_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c494a",
   "metadata": {},
   "source": [
    "FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9582256",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeatureExtractor()\n",
    "X = extractor.extract_fused_features_bert(df)\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d94b1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = ModelEvaluator(model_type='svm', n_splits= 10, random_state=32)\n",
    "results = evaluator.cross_validate_with_confusionmatrix(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948f670c",
   "metadata": {},
   "source": [
    "Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5833bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "trainer = BaselineTrainer(model_type='svm')\n",
    "model = trainer.train(X_embed_bal, y_bal)\n",
    "\n",
    "new_text = \"Apakah kamu suddah makan?\"\n",
    "clean_text = text_preprocessor.preprocess(new_text)\n",
    "X_new = extractor.encode_series_bert([clean_text])\n",
    "predicted_label = model.predict(X_new)[0]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e0bd345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "new_text = \"Apakah kamu sudah makan?\"\n",
    "clean_text = text_preprocessor.preprocess(new_text)\n",
    "X_new = extractor.encode_series_bert([clean_text])\n",
    "predicted_label = model.predict(X_new)[0]\n",
    "print(f\"Predicted label: {predicted_label}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
